{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torchvision\n",
    "import torchvision.transforms as transforms\n",
    "from torch.utils.data import DataLoader\n",
    "import os\n",
    "from PIL import Image\n",
    "import torch.optim as optim\n",
    "from torchvision.datasets import ImageFolder\n",
    "import torch.nn.functional as F\n",
    "import numpy as np\n",
    "from sklearn.metrics import accuracy_score, precision_score, recall_score, f1_score\n",
    "import pandas as pd\n",
    "import cv2\n",
    "import os\n",
    "from keras.preprocessing import image\n",
    "from keras.applications.resnet import ResNet50, preprocess_input\n",
    "from sklearn.model_selection import train_test_split\n",
    "from keras_preprocessing.sequence import pad_sequences\n",
    "from keras.preprocessing.text import Tokenizer\n",
    "from keras.layers import Embedding, LSTM, Dense, Dropout, GlobalAveragePooling2D, GlobalMaxPooling2D, concatenate, Input, Flatten, BatchNormalization\n",
    "import torch.utils.data as data\n",
    "from torch.utils.data import DataLoader, Dataset, TensorDataset\n",
    "import torch\n",
    "import torchvision.models as models\n",
    "from torch.nn.utils.rnn import pad_sequence\n",
    "import gensim.downloader as api\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>imgid</th>\n",
       "      <th>split</th>\n",
       "      <th>filename</th>\n",
       "      <th>successful</th>\n",
       "      <th>tokens</th>\n",
       "      <th>word_sentiment</th>\n",
       "      <th>sentiment</th>\n",
       "      <th>raw</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>31369</td>\n",
       "      <td>train</td>\n",
       "      <td>COCO_val2014_000000389081.jpg</td>\n",
       "      <td>1</td>\n",
       "      <td>['a', 'plate', 'of', 'delicious', 'food', 'inc...</td>\n",
       "      <td>[0.0, 0.0, 0.0, 1, 1, 0.0, 0.0, 0.0]</td>\n",
       "      <td>1</td>\n",
       "      <td>a plate of delicious food including French fries.</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>31369</td>\n",
       "      <td>train</td>\n",
       "      <td>COCO_val2014_000000389081.jpg</td>\n",
       "      <td>1</td>\n",
       "      <td>['french', 'fries', 'are', 'not', 'a', 'health...</td>\n",
       "      <td>[0.0, 0.0, 0.0, 0.0, 0.0, 1, 1, 0.0, 0.0, 0.0,...</td>\n",
       "      <td>1</td>\n",
       "      <td>French fries are not a healthy food but it is ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>31369</td>\n",
       "      <td>train</td>\n",
       "      <td>COCO_val2014_000000389081.jpg</td>\n",
       "      <td>1</td>\n",
       "      <td>['the', 'plate', 'has', 'one', 'of', 'my', 'fa...</td>\n",
       "      <td>[0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 1, 1, 0.0, 0.0,...</td>\n",
       "      <td>1</td>\n",
       "      <td>The plate has one of my favorite foods on it, ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>31369</td>\n",
       "      <td>train</td>\n",
       "      <td>COCO_val2014_000000389081.jpg</td>\n",
       "      <td>1</td>\n",
       "      <td>['it', 'was', 'disgusting', 'food', 'not', 'ju...</td>\n",
       "      <td>[0.0, 0.0, 1, 1, 0.0, 0.0, 1, 1]</td>\n",
       "      <td>0</td>\n",
       "      <td>It was disgusting food, not just bad food.</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>31369</td>\n",
       "      <td>train</td>\n",
       "      <td>COCO_val2014_000000389081.jpg</td>\n",
       "      <td>1</td>\n",
       "      <td>['a', 'plate', 'of', 'disgusting', 'food', 'fo...</td>\n",
       "      <td>[0.0, 0.0, 0.0, 1, 1, 0.0, 0.0, 0.0, 0.0]</td>\n",
       "      <td>0</td>\n",
       "      <td>A plate of disgusting food found at a diner.</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   imgid  split                       filename  successful  \\\n",
       "0  31369  train  COCO_val2014_000000389081.jpg           1   \n",
       "1  31369  train  COCO_val2014_000000389081.jpg           1   \n",
       "2  31369  train  COCO_val2014_000000389081.jpg           1   \n",
       "3  31369  train  COCO_val2014_000000389081.jpg           1   \n",
       "4  31369  train  COCO_val2014_000000389081.jpg           1   \n",
       "\n",
       "                                              tokens  \\\n",
       "0  ['a', 'plate', 'of', 'delicious', 'food', 'inc...   \n",
       "1  ['french', 'fries', 'are', 'not', 'a', 'health...   \n",
       "2  ['the', 'plate', 'has', 'one', 'of', 'my', 'fa...   \n",
       "3  ['it', 'was', 'disgusting', 'food', 'not', 'ju...   \n",
       "4  ['a', 'plate', 'of', 'disgusting', 'food', 'fo...   \n",
       "\n",
       "                                      word_sentiment  sentiment  \\\n",
       "0               [0.0, 0.0, 0.0, 1, 1, 0.0, 0.0, 0.0]          1   \n",
       "1  [0.0, 0.0, 0.0, 0.0, 0.0, 1, 1, 0.0, 0.0, 0.0,...          1   \n",
       "2  [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 1, 1, 0.0, 0.0,...          1   \n",
       "3                   [0.0, 0.0, 1, 1, 0.0, 0.0, 1, 1]          0   \n",
       "4          [0.0, 0.0, 0.0, 1, 1, 0.0, 0.0, 0.0, 0.0]          0   \n",
       "\n",
       "                                                 raw  \n",
       "0  a plate of delicious food including French fries.  \n",
       "1  French fries are not a healthy food but it is ...  \n",
       "2  The plate has one of my favorite foods on it, ...  \n",
       "3         It was disgusting food, not just bad food.  \n",
       "4       A plate of disgusting food found at a diner.  "
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df = pd.read_csv('sentiment.csv')\n",
    "df.drop(df.columns[0], axis=1, inplace=True)\n",
    "df.head()"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Text Preprocessing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>imgid</th>\n",
       "      <th>split</th>\n",
       "      <th>filename</th>\n",
       "      <th>successful</th>\n",
       "      <th>tokens</th>\n",
       "      <th>word_sentiment</th>\n",
       "      <th>sentiment</th>\n",
       "      <th>raw</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>31369</td>\n",
       "      <td>train</td>\n",
       "      <td>COCO_val2014_000000389081.jpg</td>\n",
       "      <td>1</td>\n",
       "      <td>[a, plate, of, delicious, food, including, fre...</td>\n",
       "      <td>[0.0, 0.0, 0.0, 1, 1, 0.0, 0.0, 0.0]</td>\n",
       "      <td>1</td>\n",
       "      <td>a plate of delicious food including French fries.</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>31369</td>\n",
       "      <td>train</td>\n",
       "      <td>COCO_val2014_000000389081.jpg</td>\n",
       "      <td>1</td>\n",
       "      <td>[french, fries, are, not, a, healthy, food, bu...</td>\n",
       "      <td>[0.0, 0.0, 0.0, 0.0, 0.0, 1, 1, 0.0, 0.0, 0.0,...</td>\n",
       "      <td>1</td>\n",
       "      <td>French fries are not a healthy food but it is ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>31369</td>\n",
       "      <td>train</td>\n",
       "      <td>COCO_val2014_000000389081.jpg</td>\n",
       "      <td>1</td>\n",
       "      <td>[the, plate, has, one, of, my, favorite, foods...</td>\n",
       "      <td>[0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 1, 1, 0.0, 0.0,...</td>\n",
       "      <td>1</td>\n",
       "      <td>The plate has one of my favorite foods on it, ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>31369</td>\n",
       "      <td>train</td>\n",
       "      <td>COCO_val2014_000000389081.jpg</td>\n",
       "      <td>1</td>\n",
       "      <td>[it, was, disgusting, food, not, just, bad, food]</td>\n",
       "      <td>[0.0, 0.0, 1, 1, 0.0, 0.0, 1, 1]</td>\n",
       "      <td>0</td>\n",
       "      <td>It was disgusting food, not just bad food.</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>31369</td>\n",
       "      <td>train</td>\n",
       "      <td>COCO_val2014_000000389081.jpg</td>\n",
       "      <td>1</td>\n",
       "      <td>[a, plate, of, disgusting, food, found, at, a,...</td>\n",
       "      <td>[0.0, 0.0, 0.0, 1, 1, 0.0, 0.0, 0.0, 0.0]</td>\n",
       "      <td>0</td>\n",
       "      <td>A plate of disgusting food found at a diner.</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>39194</th>\n",
       "      <td>24628</td>\n",
       "      <td>test</td>\n",
       "      <td>COCO_val2014_000000190705.jpg</td>\n",
       "      <td>1</td>\n",
       "      <td>[a, dirty, bathroom, that, has, a, dirty, wind...</td>\n",
       "      <td>[0.0, 1, 1, 0.0, 0.0, 0.0, 1, 1, 0.0, 0.0, 1, 1]</td>\n",
       "      <td>0</td>\n",
       "      <td>A dirty bathroom that has a dirty window made ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>39195</th>\n",
       "      <td>24628</td>\n",
       "      <td>test</td>\n",
       "      <td>COCO_val2014_000000190705.jpg</td>\n",
       "      <td>1</td>\n",
       "      <td>[a, dirty, bathroom, that, has, a, window, in,...</td>\n",
       "      <td>[0.0, 1, 1, 0.0, 0.0, 0.0, 1, 0.0, 0.0]</td>\n",
       "      <td>0</td>\n",
       "      <td>A dirty bathroom that has a window in it.</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>39196</th>\n",
       "      <td>24628</td>\n",
       "      <td>test</td>\n",
       "      <td>COCO_val2014_000000190705.jpg</td>\n",
       "      <td>1</td>\n",
       "      <td>[a, towel, that, is, on, a, rack, in, a, dirty...</td>\n",
       "      <td>[0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, ...</td>\n",
       "      <td>0</td>\n",
       "      <td>a towel that is on a rack in a dirty bathroom</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>39197</th>\n",
       "      <td>24628</td>\n",
       "      <td>test</td>\n",
       "      <td>COCO_val2014_000000190705.jpg</td>\n",
       "      <td>1</td>\n",
       "      <td>[a, dirty, bathroom, that, has, a, dirty, wind...</td>\n",
       "      <td>[0.0, 1, 1, 0.0, 0.0, 0.0, 1, 1, 0.0, 0.0, 1, 1]</td>\n",
       "      <td>0</td>\n",
       "      <td>A dirty bathroom that has a dirty window made ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>39198</th>\n",
       "      <td>24628</td>\n",
       "      <td>test</td>\n",
       "      <td>COCO_val2014_000000190705.jpg</td>\n",
       "      <td>1</td>\n",
       "      <td>[a, dirty, bathroom, that, has, a, window, in,...</td>\n",
       "      <td>[0.0, 1, 1, 0.0, 0.0, 0.0, 1, 0.0, 0.0]</td>\n",
       "      <td>0</td>\n",
       "      <td>A dirty bathroom that has a window in it.</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>39199 rows × 8 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "       imgid  split                       filename  successful  \\\n",
       "0      31369  train  COCO_val2014_000000389081.jpg           1   \n",
       "1      31369  train  COCO_val2014_000000389081.jpg           1   \n",
       "2      31369  train  COCO_val2014_000000389081.jpg           1   \n",
       "3      31369  train  COCO_val2014_000000389081.jpg           1   \n",
       "4      31369  train  COCO_val2014_000000389081.jpg           1   \n",
       "...      ...    ...                            ...         ...   \n",
       "39194  24628   test  COCO_val2014_000000190705.jpg           1   \n",
       "39195  24628   test  COCO_val2014_000000190705.jpg           1   \n",
       "39196  24628   test  COCO_val2014_000000190705.jpg           1   \n",
       "39197  24628   test  COCO_val2014_000000190705.jpg           1   \n",
       "39198  24628   test  COCO_val2014_000000190705.jpg           1   \n",
       "\n",
       "                                                  tokens  \\\n",
       "0      [a, plate, of, delicious, food, including, fre...   \n",
       "1      [french, fries, are, not, a, healthy, food, bu...   \n",
       "2      [the, plate, has, one, of, my, favorite, foods...   \n",
       "3      [it, was, disgusting, food, not, just, bad, food]   \n",
       "4      [a, plate, of, disgusting, food, found, at, a,...   \n",
       "...                                                  ...   \n",
       "39194  [a, dirty, bathroom, that, has, a, dirty, wind...   \n",
       "39195  [a, dirty, bathroom, that, has, a, window, in,...   \n",
       "39196  [a, towel, that, is, on, a, rack, in, a, dirty...   \n",
       "39197  [a, dirty, bathroom, that, has, a, dirty, wind...   \n",
       "39198  [a, dirty, bathroom, that, has, a, window, in,...   \n",
       "\n",
       "                                          word_sentiment  sentiment  \\\n",
       "0                   [0.0, 0.0, 0.0, 1, 1, 0.0, 0.0, 0.0]          1   \n",
       "1      [0.0, 0.0, 0.0, 0.0, 0.0, 1, 1, 0.0, 0.0, 0.0,...          1   \n",
       "2      [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 1, 1, 0.0, 0.0,...          1   \n",
       "3                       [0.0, 0.0, 1, 1, 0.0, 0.0, 1, 1]          0   \n",
       "4              [0.0, 0.0, 0.0, 1, 1, 0.0, 0.0, 0.0, 0.0]          0   \n",
       "...                                                  ...        ...   \n",
       "39194   [0.0, 1, 1, 0.0, 0.0, 0.0, 1, 1, 0.0, 0.0, 1, 1]          0   \n",
       "39195            [0.0, 1, 1, 0.0, 0.0, 0.0, 1, 0.0, 0.0]          0   \n",
       "39196  [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, ...          0   \n",
       "39197   [0.0, 1, 1, 0.0, 0.0, 0.0, 1, 1, 0.0, 0.0, 1, 1]          0   \n",
       "39198            [0.0, 1, 1, 0.0, 0.0, 0.0, 1, 0.0, 0.0]          0   \n",
       "\n",
       "                                                     raw  \n",
       "0      a plate of delicious food including French fries.  \n",
       "1      French fries are not a healthy food but it is ...  \n",
       "2      The plate has one of my favorite foods on it, ...  \n",
       "3             It was disgusting food, not just bad food.  \n",
       "4           A plate of disgusting food found at a diner.  \n",
       "...                                                  ...  \n",
       "39194  A dirty bathroom that has a dirty window made ...  \n",
       "39195          A dirty bathroom that has a window in it.  \n",
       "39196      a towel that is on a rack in a dirty bathroom  \n",
       "39197  A dirty bathroom that has a dirty window made ...  \n",
       "39198          A dirty bathroom that has a window in it.  \n",
       "\n",
       "[39199 rows x 8 columns]"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Define a lambda function to remove quotes from words in a list\n",
    "def remove_quotes(lst): return [word.strip(\"'\") for word in lst]\n",
    "\n",
    "# Apply the lambda function to the 'text' column of the dataframe\n",
    "df['tokens'] = df['tokens'].apply(lambda x: remove_quotes(eval(x)))\n",
    "\n",
    "# Print the resulting dataframe\n",
    "df\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>imgid</th>\n",
       "      <th>split</th>\n",
       "      <th>filename</th>\n",
       "      <th>successful</th>\n",
       "      <th>tokens</th>\n",
       "      <th>word_sentiment</th>\n",
       "      <th>sentiment</th>\n",
       "      <th>raw</th>\n",
       "      <th>text_features</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>31369</td>\n",
       "      <td>train</td>\n",
       "      <td>COCO_val2014_000000389081.jpg</td>\n",
       "      <td>1</td>\n",
       "      <td>[a, plate, of, delicious, food, including, fre...</td>\n",
       "      <td>[0.0, 0.0, 0.0, 1, 1, 0.0, 0.0, 0.0]</td>\n",
       "      <td>1</td>\n",
       "      <td>a plate of delicious food including French fries.</td>\n",
       "      <td>[[tensor(-0.2709), tensor(0.0440), tensor(-0.0...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>31369</td>\n",
       "      <td>train</td>\n",
       "      <td>COCO_val2014_000000389081.jpg</td>\n",
       "      <td>1</td>\n",
       "      <td>[french, fries, are, not, a, healthy, food, bu...</td>\n",
       "      <td>[0.0, 0.0, 0.0, 0.0, 0.0, 1, 1, 0.0, 0.0, 0.0,...</td>\n",
       "      <td>1</td>\n",
       "      <td>French fries are not a healthy food but it is ...</td>\n",
       "      <td>[[tensor(0.0270), tensor(-0.0538), tensor(0.16...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   imgid  split                       filename  successful  \\\n",
       "0  31369  train  COCO_val2014_000000389081.jpg           1   \n",
       "1  31369  train  COCO_val2014_000000389081.jpg           1   \n",
       "\n",
       "                                              tokens  \\\n",
       "0  [a, plate, of, delicious, food, including, fre...   \n",
       "1  [french, fries, are, not, a, healthy, food, bu...   \n",
       "\n",
       "                                      word_sentiment  sentiment  \\\n",
       "0               [0.0, 0.0, 0.0, 1, 1, 0.0, 0.0, 0.0]          1   \n",
       "1  [0.0, 0.0, 0.0, 0.0, 0.0, 1, 1, 0.0, 0.0, 0.0,...          1   \n",
       "\n",
       "                                                 raw  \\\n",
       "0  a plate of delicious food including French fries.   \n",
       "1  French fries are not a healthy food but it is ...   \n",
       "\n",
       "                                       text_features  \n",
       "0  [[tensor(-0.2709), tensor(0.0440), tensor(-0.0...  \n",
       "1  [[tensor(0.0270), tensor(-0.0538), tensor(0.16...  "
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Load the GloVe word embeddings\n",
    "# Load the 'glove-wiki-gigaword-100' embeddings\n",
    "glove_model = api.load('glove-wiki-gigaword-100')\n",
    "\n",
    "\n",
    "def get_word_embeddings(word):\n",
    "    if word in glove_model:\n",
    "        return glove_model[word]\n",
    "    else:\n",
    "        return np.zeros(100)\n",
    "\n",
    "\n",
    "def embedding(tokens):\n",
    "    embeddings = np.array([get_word_embeddings(word) for word in tokens])\n",
    "    return embeddings\n",
    "\n",
    "\n",
    "# Convert sample_captions['cleaned_caption'] to numerical_caption using embeddings\n",
    "df['text_features'] = df['tokens'].apply(embedding)\n",
    "\n",
    "df['text_features'] = df['text_features'].apply(torch.tensor)\n",
    "\n",
    "df.head(2)\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Resizing and normalizing the images"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Python310\\lib\\site-packages\\torchvision\\models\\_utils.py:208: UserWarning: The parameter 'pretrained' is deprecated since 0.13 and may be removed in the future, please use 'weights' instead.\n",
      "  warnings.warn(\n",
      "c:\\Python310\\lib\\site-packages\\torchvision\\models\\_utils.py:223: UserWarning: Arguments other than a weight enum or `None` for 'weights' are deprecated since 0.13 and may be removed in the future. The current behavior is equivalent to passing `weights=ResNet50_Weights.IMAGENET1K_V1`. You can also use `weights=ResNet50_Weights.DEFAULT` to get the most up-to-date weights.\n",
      "  warnings.warn(msg)\n"
     ]
    }
   ],
   "source": [
    "model = models.resnet50(pretrained=True)\n",
    "model = torch.nn.Sequential(*list(model.children())[:-1])\n",
    "model.eval()\n",
    "transform = transforms.Compose([\n",
    "    transforms.Resize((224, 224)),\n",
    "    transforms.ToTensor(),\n",
    "    transforms.Normalize(mean=[0.485, 0.456, 0.406],\n",
    "                         std=[0.229, 0.224, 0.225])\n",
    "])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def extract_features(folder_path):\n",
    "    features = {}\n",
    "    for file in os.listdir(folder_path):\n",
    "        img_path = os.path.join(folder_path, file)\n",
    "        img = Image.open(img_path).convert(\"RGB\")\n",
    "        img_tensor = transform(img)\n",
    "        img_tensor = img_tensor.unsqueeze(0)\n",
    "        with torch.no_grad():\n",
    "            features_tensor = model(img_tensor)\n",
    "        features_np = torch.squeeze(features_tensor)\n",
    "        features[file] = features_np\n",
    "    return features\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "folder_path = 'sentiment_images'\n",
    "image_features = extract_features(folder_path)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "# Create a new list to store the values from the dictionary\n",
    "imageFeatures = []\n",
    "\n",
    "# Iterate through the rows of the DataFrame\n",
    "for index, row in df.iterrows():\n",
    "    # Check if the value in 'col1' matches a key in the dictionary\n",
    "    if row['filename'] in image_features:\n",
    "        # If there is a match, append the corresponding value to the new list\n",
    "        imageFeatures.append(image_features[row['filename']])\n",
    "    else:\n",
    "        # If there is no match, append NaN to the new list\n",
    "        imageFeatures.append(torch.tensor(float('nan')))\n",
    "        \n",
    "\n",
    "\n",
    "# Add the new list as a new column in the DataFrame\n",
    "df['image_features'] = imageFeatures\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_copy = df.copy()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Aeiman Imtiaz\\AppData\\Local\\Temp\\ipykernel_14472\\1327902967.py:1: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  df_copy = df_copy[df_copy.apply(lambda x: torch.tensor(x['image_features']).numel() != 0, axis=1)]\n"
     ]
    }
   ],
   "source": [
    "df_copy = df_copy[df_copy.apply(lambda x: torch.tensor(x['image_features']).numel() != 0, axis=1)]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Aeiman Imtiaz\\AppData\\Local\\Temp\\ipykernel_14472\\3422520640.py:3: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  if torch.tensor(features).shape == torch.Size([]):\n",
      "C:\\Users\\Aeiman Imtiaz\\AppData\\Local\\Temp\\ipykernel_14472\\3422520640.py:3: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  if torch.tensor(features).shape == torch.Size([]):\n",
      "C:\\Users\\Aeiman Imtiaz\\AppData\\Local\\Temp\\ipykernel_14472\\3422520640.py:3: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  if torch.tensor(features).shape == torch.Size([]):\n",
      "C:\\Users\\Aeiman Imtiaz\\AppData\\Local\\Temp\\ipykernel_14472\\3422520640.py:3: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  if torch.tensor(features).shape == torch.Size([]):\n",
      "C:\\Users\\Aeiman Imtiaz\\AppData\\Local\\Temp\\ipykernel_14472\\3422520640.py:3: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  if torch.tensor(features).shape == torch.Size([]):\n",
      "C:\\Users\\Aeiman Imtiaz\\AppData\\Local\\Temp\\ipykernel_14472\\3422520640.py:3: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  if torch.tensor(features).shape == torch.Size([]):\n",
      "C:\\Users\\Aeiman Imtiaz\\AppData\\Local\\Temp\\ipykernel_14472\\3422520640.py:3: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  if torch.tensor(features).shape == torch.Size([]):\n",
      "C:\\Users\\Aeiman Imtiaz\\AppData\\Local\\Temp\\ipykernel_14472\\3422520640.py:3: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  if torch.tensor(features).shape == torch.Size([]):\n",
      "C:\\Users\\Aeiman Imtiaz\\AppData\\Local\\Temp\\ipykernel_14472\\3422520640.py:3: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  if torch.tensor(features).shape == torch.Size([]):\n",
      "C:\\Users\\Aeiman Imtiaz\\AppData\\Local\\Temp\\ipykernel_14472\\3422520640.py:3: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  if torch.tensor(features).shape == torch.Size([]):\n",
      "C:\\Users\\Aeiman Imtiaz\\AppData\\Local\\Temp\\ipykernel_14472\\3422520640.py:3: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  if torch.tensor(features).shape == torch.Size([]):\n",
      "C:\\Users\\Aeiman Imtiaz\\AppData\\Local\\Temp\\ipykernel_14472\\3422520640.py:3: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  if torch.tensor(features).shape == torch.Size([]):\n",
      "C:\\Users\\Aeiman Imtiaz\\AppData\\Local\\Temp\\ipykernel_14472\\3422520640.py:3: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  if torch.tensor(features).shape == torch.Size([]):\n",
      "C:\\Users\\Aeiman Imtiaz\\AppData\\Local\\Temp\\ipykernel_14472\\3422520640.py:3: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  if torch.tensor(features).shape == torch.Size([]):\n",
      "C:\\Users\\Aeiman Imtiaz\\AppData\\Local\\Temp\\ipykernel_14472\\3422520640.py:3: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  if torch.tensor(features).shape == torch.Size([]):\n",
      "C:\\Users\\Aeiman Imtiaz\\AppData\\Local\\Temp\\ipykernel_14472\\3422520640.py:3: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  if torch.tensor(features).shape == torch.Size([]):\n",
      "C:\\Users\\Aeiman Imtiaz\\AppData\\Local\\Temp\\ipykernel_14472\\3422520640.py:3: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  if torch.tensor(features).shape == torch.Size([]):\n",
      "C:\\Users\\Aeiman Imtiaz\\AppData\\Local\\Temp\\ipykernel_14472\\3422520640.py:3: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  if torch.tensor(features).shape == torch.Size([]):\n",
      "C:\\Users\\Aeiman Imtiaz\\AppData\\Local\\Temp\\ipykernel_14472\\3422520640.py:3: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  if torch.tensor(features).shape == torch.Size([]):\n",
      "C:\\Users\\Aeiman Imtiaz\\AppData\\Local\\Temp\\ipykernel_14472\\3422520640.py:3: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  if torch.tensor(features).shape == torch.Size([]):\n",
      "C:\\Users\\Aeiman Imtiaz\\AppData\\Local\\Temp\\ipykernel_14472\\3422520640.py:3: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  if torch.tensor(features).shape == torch.Size([]):\n",
      "C:\\Users\\Aeiman Imtiaz\\AppData\\Local\\Temp\\ipykernel_14472\\3422520640.py:3: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  if torch.tensor(features).shape == torch.Size([]):\n",
      "C:\\Users\\Aeiman Imtiaz\\AppData\\Local\\Temp\\ipykernel_14472\\3422520640.py:3: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  if torch.tensor(features).shape == torch.Size([]):\n",
      "C:\\Users\\Aeiman Imtiaz\\AppData\\Local\\Temp\\ipykernel_14472\\3422520640.py:3: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  if torch.tensor(features).shape == torch.Size([]):\n",
      "C:\\Users\\Aeiman Imtiaz\\AppData\\Local\\Temp\\ipykernel_14472\\3422520640.py:3: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  if torch.tensor(features).shape == torch.Size([]):\n",
      "C:\\Users\\Aeiman Imtiaz\\AppData\\Local\\Temp\\ipykernel_14472\\3422520640.py:3: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  if torch.tensor(features).shape == torch.Size([]):\n",
      "C:\\Users\\Aeiman Imtiaz\\AppData\\Local\\Temp\\ipykernel_14472\\3422520640.py:3: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  if torch.tensor(features).shape == torch.Size([]):\n",
      "C:\\Users\\Aeiman Imtiaz\\AppData\\Local\\Temp\\ipykernel_14472\\3422520640.py:3: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  if torch.tensor(features).shape == torch.Size([]):\n",
      "C:\\Users\\Aeiman Imtiaz\\AppData\\Local\\Temp\\ipykernel_14472\\3422520640.py:3: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  if torch.tensor(features).shape == torch.Size([]):\n",
      "C:\\Users\\Aeiman Imtiaz\\AppData\\Local\\Temp\\ipykernel_14472\\3422520640.py:3: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  if torch.tensor(features).shape == torch.Size([]):\n",
      "C:\\Users\\Aeiman Imtiaz\\AppData\\Local\\Temp\\ipykernel_14472\\3422520640.py:3: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  if torch.tensor(features).shape == torch.Size([]):\n",
      "C:\\Users\\Aeiman Imtiaz\\AppData\\Local\\Temp\\ipykernel_14472\\3422520640.py:3: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  if torch.tensor(features).shape == torch.Size([]):\n",
      "C:\\Users\\Aeiman Imtiaz\\AppData\\Local\\Temp\\ipykernel_14472\\3422520640.py:3: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  if torch.tensor(features).shape == torch.Size([]):\n",
      "C:\\Users\\Aeiman Imtiaz\\AppData\\Local\\Temp\\ipykernel_14472\\3422520640.py:3: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  if torch.tensor(features).shape == torch.Size([]):\n",
      "C:\\Users\\Aeiman Imtiaz\\AppData\\Local\\Temp\\ipykernel_14472\\3422520640.py:3: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  if torch.tensor(features).shape == torch.Size([]):\n",
      "C:\\Users\\Aeiman Imtiaz\\AppData\\Local\\Temp\\ipykernel_14472\\3422520640.py:3: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  if torch.tensor(features).shape == torch.Size([]):\n",
      "C:\\Users\\Aeiman Imtiaz\\AppData\\Local\\Temp\\ipykernel_14472\\3422520640.py:3: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  if torch.tensor(features).shape == torch.Size([]):\n",
      "C:\\Users\\Aeiman Imtiaz\\AppData\\Local\\Temp\\ipykernel_14472\\3422520640.py:3: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  if torch.tensor(features).shape == torch.Size([]):\n",
      "C:\\Users\\Aeiman Imtiaz\\AppData\\Local\\Temp\\ipykernel_14472\\3422520640.py:3: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  if torch.tensor(features).shape == torch.Size([]):\n",
      "C:\\Users\\Aeiman Imtiaz\\AppData\\Local\\Temp\\ipykernel_14472\\3422520640.py:3: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  if torch.tensor(features).shape == torch.Size([]):\n",
      "C:\\Users\\Aeiman Imtiaz\\AppData\\Local\\Temp\\ipykernel_14472\\3422520640.py:3: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  if torch.tensor(features).shape == torch.Size([]):\n",
      "C:\\Users\\Aeiman Imtiaz\\AppData\\Local\\Temp\\ipykernel_14472\\3422520640.py:3: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  if torch.tensor(features).shape == torch.Size([]):\n",
      "C:\\Users\\Aeiman Imtiaz\\AppData\\Local\\Temp\\ipykernel_14472\\3422520640.py:3: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  if torch.tensor(features).shape == torch.Size([]):\n",
      "C:\\Users\\Aeiman Imtiaz\\AppData\\Local\\Temp\\ipykernel_14472\\3422520640.py:3: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  if torch.tensor(features).shape == torch.Size([]):\n",
      "C:\\Users\\Aeiman Imtiaz\\AppData\\Local\\Temp\\ipykernel_14472\\3422520640.py:3: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  if torch.tensor(features).shape == torch.Size([]):\n",
      "C:\\Users\\Aeiman Imtiaz\\AppData\\Local\\Temp\\ipykernel_14472\\3422520640.py:3: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  if torch.tensor(features).shape == torch.Size([]):\n",
      "C:\\Users\\Aeiman Imtiaz\\AppData\\Local\\Temp\\ipykernel_14472\\3422520640.py:3: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  if torch.tensor(features).shape == torch.Size([]):\n",
      "C:\\Users\\Aeiman Imtiaz\\AppData\\Local\\Temp\\ipykernel_14472\\3422520640.py:3: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  if torch.tensor(features).shape == torch.Size([]):\n",
      "C:\\Users\\Aeiman Imtiaz\\AppData\\Local\\Temp\\ipykernel_14472\\3422520640.py:3: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  if torch.tensor(features).shape == torch.Size([]):\n",
      "C:\\Users\\Aeiman Imtiaz\\AppData\\Local\\Temp\\ipykernel_14472\\3422520640.py:3: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  if torch.tensor(features).shape == torch.Size([]):\n",
      "C:\\Users\\Aeiman Imtiaz\\AppData\\Local\\Temp\\ipykernel_14472\\3422520640.py:3: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  if torch.tensor(features).shape == torch.Size([]):\n",
      "C:\\Users\\Aeiman Imtiaz\\AppData\\Local\\Temp\\ipykernel_14472\\3422520640.py:3: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  if torch.tensor(features).shape == torch.Size([]):\n",
      "C:\\Users\\Aeiman Imtiaz\\AppData\\Local\\Temp\\ipykernel_14472\\3422520640.py:3: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  if torch.tensor(features).shape == torch.Size([]):\n",
      "C:\\Users\\Aeiman Imtiaz\\AppData\\Local\\Temp\\ipykernel_14472\\3422520640.py:3: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  if torch.tensor(features).shape == torch.Size([]):\n",
      "C:\\Users\\Aeiman Imtiaz\\AppData\\Local\\Temp\\ipykernel_14472\\3422520640.py:3: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  if torch.tensor(features).shape == torch.Size([]):\n",
      "C:\\Users\\Aeiman Imtiaz\\AppData\\Local\\Temp\\ipykernel_14472\\3422520640.py:3: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  if torch.tensor(features).shape == torch.Size([]):\n",
      "C:\\Users\\Aeiman Imtiaz\\AppData\\Local\\Temp\\ipykernel_14472\\3422520640.py:3: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  if torch.tensor(features).shape == torch.Size([]):\n",
      "C:\\Users\\Aeiman Imtiaz\\AppData\\Local\\Temp\\ipykernel_14472\\3422520640.py:3: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  if torch.tensor(features).shape == torch.Size([]):\n",
      "C:\\Users\\Aeiman Imtiaz\\AppData\\Local\\Temp\\ipykernel_14472\\3422520640.py:3: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  if torch.tensor(features).shape == torch.Size([]):\n",
      "C:\\Users\\Aeiman Imtiaz\\AppData\\Local\\Temp\\ipykernel_14472\\3422520640.py:3: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  if torch.tensor(features).shape == torch.Size([]):\n",
      "C:\\Users\\Aeiman Imtiaz\\AppData\\Local\\Temp\\ipykernel_14472\\3422520640.py:3: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  if torch.tensor(features).shape == torch.Size([]):\n",
      "C:\\Users\\Aeiman Imtiaz\\AppData\\Local\\Temp\\ipykernel_14472\\3422520640.py:3: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  if torch.tensor(features).shape == torch.Size([]):\n",
      "C:\\Users\\Aeiman Imtiaz\\AppData\\Local\\Temp\\ipykernel_14472\\3422520640.py:3: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  if torch.tensor(features).shape == torch.Size([]):\n",
      "C:\\Users\\Aeiman Imtiaz\\AppData\\Local\\Temp\\ipykernel_14472\\3422520640.py:3: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  if torch.tensor(features).shape == torch.Size([]):\n",
      "C:\\Users\\Aeiman Imtiaz\\AppData\\Local\\Temp\\ipykernel_14472\\3422520640.py:3: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  if torch.tensor(features).shape == torch.Size([]):\n",
      "C:\\Users\\Aeiman Imtiaz\\AppData\\Local\\Temp\\ipykernel_14472\\3422520640.py:3: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  if torch.tensor(features).shape == torch.Size([]):\n",
      "C:\\Users\\Aeiman Imtiaz\\AppData\\Local\\Temp\\ipykernel_14472\\3422520640.py:3: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  if torch.tensor(features).shape == torch.Size([]):\n",
      "C:\\Users\\Aeiman Imtiaz\\AppData\\Local\\Temp\\ipykernel_14472\\3422520640.py:3: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  if torch.tensor(features).shape == torch.Size([]):\n",
      "C:\\Users\\Aeiman Imtiaz\\AppData\\Local\\Temp\\ipykernel_14472\\3422520640.py:3: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  if torch.tensor(features).shape == torch.Size([]):\n",
      "C:\\Users\\Aeiman Imtiaz\\AppData\\Local\\Temp\\ipykernel_14472\\3422520640.py:3: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  if torch.tensor(features).shape == torch.Size([]):\n",
      "C:\\Users\\Aeiman Imtiaz\\AppData\\Local\\Temp\\ipykernel_14472\\3422520640.py:3: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  if torch.tensor(features).shape == torch.Size([]):\n",
      "C:\\Users\\Aeiman Imtiaz\\AppData\\Local\\Temp\\ipykernel_14472\\3422520640.py:3: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  if torch.tensor(features).shape == torch.Size([]):\n",
      "C:\\Users\\Aeiman Imtiaz\\AppData\\Local\\Temp\\ipykernel_14472\\3422520640.py:3: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  if torch.tensor(features).shape == torch.Size([]):\n",
      "C:\\Users\\Aeiman Imtiaz\\AppData\\Local\\Temp\\ipykernel_14472\\3422520640.py:3: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  if torch.tensor(features).shape == torch.Size([]):\n",
      "C:\\Users\\Aeiman Imtiaz\\AppData\\Local\\Temp\\ipykernel_14472\\3422520640.py:3: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  if torch.tensor(features).shape == torch.Size([]):\n",
      "C:\\Users\\Aeiman Imtiaz\\AppData\\Local\\Temp\\ipykernel_14472\\3422520640.py:3: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  if torch.tensor(features).shape == torch.Size([]):\n",
      "C:\\Users\\Aeiman Imtiaz\\AppData\\Local\\Temp\\ipykernel_14472\\3422520640.py:3: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  if torch.tensor(features).shape == torch.Size([]):\n",
      "C:\\Users\\Aeiman Imtiaz\\AppData\\Local\\Temp\\ipykernel_14472\\3422520640.py:3: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  if torch.tensor(features).shape == torch.Size([]):\n",
      "C:\\Users\\Aeiman Imtiaz\\AppData\\Local\\Temp\\ipykernel_14472\\3422520640.py:3: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  if torch.tensor(features).shape == torch.Size([]):\n",
      "C:\\Users\\Aeiman Imtiaz\\AppData\\Local\\Temp\\ipykernel_14472\\3422520640.py:3: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  if torch.tensor(features).shape == torch.Size([]):\n",
      "C:\\Users\\Aeiman Imtiaz\\AppData\\Local\\Temp\\ipykernel_14472\\3422520640.py:3: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  if torch.tensor(features).shape == torch.Size([]):\n",
      "C:\\Users\\Aeiman Imtiaz\\AppData\\Local\\Temp\\ipykernel_14472\\3422520640.py:3: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  if torch.tensor(features).shape == torch.Size([]):\n",
      "C:\\Users\\Aeiman Imtiaz\\AppData\\Local\\Temp\\ipykernel_14472\\3422520640.py:3: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  if torch.tensor(features).shape == torch.Size([]):\n",
      "C:\\Users\\Aeiman Imtiaz\\AppData\\Local\\Temp\\ipykernel_14472\\3422520640.py:3: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  if torch.tensor(features).shape == torch.Size([]):\n",
      "C:\\Users\\Aeiman Imtiaz\\AppData\\Local\\Temp\\ipykernel_14472\\3422520640.py:3: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  if torch.tensor(features).shape == torch.Size([]):\n",
      "C:\\Users\\Aeiman Imtiaz\\AppData\\Local\\Temp\\ipykernel_14472\\3422520640.py:3: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  if torch.tensor(features).shape == torch.Size([]):\n",
      "C:\\Users\\Aeiman Imtiaz\\AppData\\Local\\Temp\\ipykernel_14472\\3422520640.py:3: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  if torch.tensor(features).shape == torch.Size([]):\n",
      "C:\\Users\\Aeiman Imtiaz\\AppData\\Local\\Temp\\ipykernel_14472\\3422520640.py:3: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  if torch.tensor(features).shape == torch.Size([]):\n",
      "C:\\Users\\Aeiman Imtiaz\\AppData\\Local\\Temp\\ipykernel_14472\\3422520640.py:3: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  if torch.tensor(features).shape == torch.Size([]):\n",
      "C:\\Users\\Aeiman Imtiaz\\AppData\\Local\\Temp\\ipykernel_14472\\3422520640.py:3: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  if torch.tensor(features).shape == torch.Size([]):\n",
      "C:\\Users\\Aeiman Imtiaz\\AppData\\Local\\Temp\\ipykernel_14472\\3422520640.py:3: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  if torch.tensor(features).shape == torch.Size([]):\n"
     ]
    }
   ],
   "source": [
    "# Drop rows with empty tensors\n",
    "for i, features in enumerate(df_copy['image_features']):\n",
    "    if torch.tensor(features).shape == torch.Size([]):\n",
    "        df_copy.drop(i, inplace=True)\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Test Train Split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 122,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training data shape: (31287, 10)\n",
      "Testing data shape: (7822, 10)\n"
     ]
    }
   ],
   "source": [
    "# Split the data into training and testing sets\n",
    "train_data, test_data = train_test_split(df_copy, test_size=0.2, random_state=1)\n",
    "train_data.reset_index(drop=True, inplace=True)\n",
    "test_data.reset_index(drop=True, inplace=True)\n",
    "\n",
    "# Print the shapes of the training and testing data\n",
    "print(\"Training data shape:\", train_data.shape)\n",
    "print(\"Testing data shape:\", test_data.shape)\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# DataLoaders"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 123,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Aeiman Imtiaz\\AppData\\Local\\Temp\\ipykernel_14472\\2505105041.py:8: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  [torch.tensor(features) for features in data['image_features'].values])\n",
      "C:\\Users\\Aeiman Imtiaz\\AppData\\Local\\Temp\\ipykernel_14472\\2505105041.py:11: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  text_features = pad_sequence([torch.tensor(\n"
     ]
    }
   ],
   "source": [
    "import math\n",
    "\n",
    "# Define a function to create the dataset\n",
    "\n",
    "\n",
    "def create_dataset(data, batch_size):\n",
    "    image_features = torch.stack(\n",
    "        [torch.tensor(features) for features in data['image_features'].values])\n",
    "    captions = [caption[:100] if len(\n",
    "        caption) > 100 else caption for caption in data['text_features'].values]\n",
    "    text_features = pad_sequence([torch.tensor(\n",
    "        caption) for caption in captions], batch_first=True, padding_value=0)\n",
    "    labels = torch.tensor(data['sentiment'])\n",
    "\n",
    "    # Define a function to get a batch from the dataset\n",
    "    def get_batch(index):\n",
    "        start_index = index * batch_size\n",
    "        end_index = (index + 1) * batch_size\n",
    "        text_batch = text_features[start_index:end_index]\n",
    "        image_batch = image_features[start_index:end_index]\n",
    "        label_batch = labels[start_index:end_index]\n",
    "\n",
    "        return text_batch, image_batch, label_batch\n",
    "\n",
    "    num_samples = len(labels)\n",
    "    num_batches = int(math.ceil(num_samples / batch_size))\n",
    "\n",
    "    return get_batch, num_batches\n",
    "\n",
    "\n",
    "batch_size = 16\n",
    "\n",
    "# Create train and validation datasets\n",
    "train_get_batch, num_train_batches = create_dataset(train_data, batch_size)\n",
    "test_get_batch, num_test_batches = create_dataset(test_data, batch_size)\n",
    "\n",
    "# Define the dataloaders using the dataset functions\n",
    "train_dataloader = DataLoader(\n",
    "    range(num_train_batches), batch_size=1, shuffle=True,\n",
    "    collate_fn=lambda x: train_get_batch(x[0]))\n",
    "test_dataloader = DataLoader(\n",
    "    range(num_test_batches), batch_size=1,\n",
    "    collate_fn=lambda x: test_get_batch(x[0]))\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Model for Sentiment Analysis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 124,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [1/10], Loss: 0.6908, Accuracy: 54.25%\n",
      "Epoch [2/10], Loss: 0.6892, Accuracy: 54.45%\n",
      "Epoch [3/10], Loss: 0.6874, Accuracy: 54.40%\n",
      "Epoch [4/10], Loss: 0.6850, Accuracy: 54.42%\n",
      "Epoch [5/10], Loss: 0.6823, Accuracy: 54.42%\n",
      "Epoch [6/10], Loss: 0.6803, Accuracy: 54.31%\n",
      "Epoch [7/10], Loss: 0.6794, Accuracy: 53.77%\n",
      "Epoch [8/10], Loss: 0.6765, Accuracy: 53.44%\n",
      "Epoch [9/10], Loss: 0.6715, Accuracy: 53.59%\n",
      "Epoch [10/10], Loss: 0.6694, Accuracy: 53.86%\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "\n",
    "# Define the model architecture\n",
    "\n",
    "\n",
    "class MultiModalSentimentAnalysis(nn.Module):\n",
    "    def __init__(self, text_input_size, image_input_size, hidden_size, num_classes):\n",
    "        super(MultiModalSentimentAnalysis, self).__init__()\n",
    "\n",
    "        # Text processing module\n",
    "        self.text_lstm = nn.LSTM(\n",
    "            text_input_size, hidden_size, batch_first=True)\n",
    "\n",
    "        # Image processing module\n",
    "        self.image_cnn = nn.Sequential(\n",
    "            nn.Linear(image_input_size, 1024),\n",
    "            nn.ReLU(),\n",
    "            nn.Linear(1024, 512),\n",
    "            nn.ReLU(),\n",
    "            nn.Linear(512, hidden_size)\n",
    "        )\n",
    "\n",
    "        # Fully-connected layer for prediction\n",
    "        self.fc = nn.Linear(hidden_size * 2, num_classes)\n",
    "\n",
    "    def forward(self, text_features, image_features):\n",
    "        # Process text features\n",
    "        text_output, _ = self.text_lstm(text_features)\n",
    "        text_output = text_output[:, -1, :]  # take last output of LSTM\n",
    "\n",
    "        # Process image features\n",
    "        image_output = self.image_cnn(image_features)\n",
    "\n",
    "        # Concatenate text and image outputs\n",
    "        combined_output = torch.cat((text_output, image_output), dim=1)\n",
    "\n",
    "        # Make prediction\n",
    "        logits = self.fc(combined_output)\n",
    "        return logits\n",
    "\n",
    "\n",
    "# Instantiate the model\n",
    "model = MultiModalSentimentAnalysis(\n",
    "    text_input_size=100, image_input_size=2048, hidden_size=256, num_classes=2)\n",
    "\n",
    "# Define the loss function and optimizer\n",
    "criterion = nn.CrossEntropyLoss()\n",
    "optimizer = optim.Adam(model.parameters())\n",
    "\n",
    "# Train the model\n",
    "num_epochs = 10\n",
    "batch_size = 16\n",
    "# Train the model\n",
    "for epoch in range(num_epochs):\n",
    "    epoch_loss = 0.0\n",
    "    epoch_acc = 0.0\n",
    "    num_batches = 0\n",
    "\n",
    "    # Loop over the batches in the dataset\n",
    "    for text_batch, image_batch, label_batch in train_dataloader:\n",
    "        # Forward pass\n",
    "        outputs = model(text_batch, image_batch)\n",
    "        loss = criterion(outputs, label_batch)\n",
    "\n",
    "        # Backward pass and optimization\n",
    "        optimizer.zero_grad()\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "\n",
    "        # Compute accuracy\n",
    "        _, predicted = torch.max(outputs, 1)\n",
    "        correct = (predicted == label_batch).sum().item()\n",
    "        total = label_batch.size(0)\n",
    "        accuracy = correct / total\n",
    "\n",
    "        # Accumulate loss and accuracy for the epoch\n",
    "        epoch_loss += loss.item()\n",
    "        epoch_acc += accuracy\n",
    "        num_batches += 1\n",
    "\n",
    "    # Print metrics for the epoch\n",
    "    epoch_loss /= num_batches\n",
    "    epoch_acc /= num_batches\n",
    "    print('Epoch [{}/{}], Loss: {:.4f}, Accuracy: {:.2f}%'.format(epoch +\n",
    "          1, num_epochs, epoch_loss, epoch_acc*100))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 126,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 53.58%\n",
      "Precision: 53.58%\n",
      "Recall: 100.00%\n",
      "F1-score: 69.77%\n"
     ]
    }
   ],
   "source": [
    "from sklearn.metrics import accuracy_score, precision_score, recall_score, f1_score\n",
    "\n",
    "# Evaluate the model on the test set\n",
    "model.eval()\n",
    "y_true = []\n",
    "y_pred = []\n",
    "\n",
    "for text_batch, image_batch, label_batch in test_dataloader:\n",
    "    # Make predictions\n",
    "    outputs = model(text_batch, image_batch)\n",
    "    _, predicted = torch.max(outputs, 1)\n",
    "\n",
    "    # Store the ground-truth labels and predicted labels\n",
    "    y_true += label_batch.tolist()\n",
    "    y_pred += predicted.tolist()\n",
    "\n",
    "# Compute metrics\n",
    "accuracy = accuracy_score(y_true, y_pred)\n",
    "precision = precision_score(y_true, y_pred)\n",
    "recall = recall_score(y_true, y_pred)\n",
    "f1 = f1_score(y_true, y_pred)\n",
    "\n",
    "print('Accuracy: {:.2f}%'.format(accuracy * 100))\n",
    "print('Precision: {:.2f}%'.format(precision * 100))\n",
    "print('Recall: {:.2f}%'.format(recall * 100))\n",
    "print('F1-score: {:.2f}%'.format(f1 * 100))\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Task 3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 127,
   "metadata": {},
   "outputs": [],
   "source": [
    "positive = df_copy['sentiment'] > 0\n",
    "df_positive = df_copy[positive]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 128,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training data shape: (16983, 10)\n",
      "Testing data shape: (4246, 10)\n"
     ]
    }
   ],
   "source": [
    "# Split the data into training and testing sets\n",
    "train_data, test_data = train_test_split(\n",
    "    df_positive, test_size=0.2, random_state=1)\n",
    "train_data.reset_index(drop=True, inplace=True)\n",
    "test_data.reset_index(drop=True, inplace=True)\n",
    "\n",
    "# Print the shapes of the training and testing data\n",
    "print(\"Training data shape:\", train_data.shape)\n",
    "print(\"Testing data shape:\", test_data.shape)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 131,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# Define the model architecture\n",
    "class MultiModalCaptionGeneration(nn.Module):\n",
    "    def __init__(self, text_input_size, image_input_size, hidden_size, vocab_size):\n",
    "        super(MultiModalCaptionGeneration, self).__init__()\n",
    "\n",
    "        # Text processing module\n",
    "        self.text_lstm = nn.LSTM(\n",
    "            text_input_size, hidden_size, batch_first=True)\n",
    "\n",
    "        # Image processing module\n",
    "        self.image_cnn = nn.Sequential(\n",
    "            nn.Linear(image_input_size, 1024),\n",
    "            nn.ReLU(),\n",
    "            nn.Linear(1024, 512),\n",
    "            nn.ReLU(),\n",
    "            nn.Linear(512, hidden_size)\n",
    "        )\n",
    "\n",
    "        # Fully-connected layer for prediction\n",
    "        self.fc = nn.Linear(hidden_size * 2, vocab_size)\n",
    "\n",
    "    def forward(self, text_features, image_features, caption=None):\n",
    "        # Process text features\n",
    "        text_output, _ = self.text_lstm(text_features)\n",
    "        text_output = text_output[:, -1, :]  # take last output of LSTM\n",
    "\n",
    "        # Process image features\n",
    "        image_output = self.image_cnn(image_features)\n",
    "\n",
    "        # Concatenate text and image outputs\n",
    "        combined_output = torch.cat((text_output, image_output), dim=1)\n",
    "\n",
    "        if caption is not None:\n",
    "            # Training mode - predict next word in caption\n",
    "            outputs = self.fc(combined_output)\n",
    "            loss = nn.CrossEntropyLoss()(outputs, caption)\n",
    "            return loss\n",
    "        else:\n",
    "            # Testing mode - generate caption\n",
    "            caption = []\n",
    "            for _ in range(20):  # maximum length of caption\n",
    "                outputs = self.fc(combined_output)\n",
    "                _, predicted = torch.max(outputs, 1)\n",
    "                caption.append(predicted.item())\n",
    "                if predicted.item() == 2:  # end of sentence token\n",
    "                    break\n",
    "                word_embedding = self.fc.weight[predicted.item()].unsqueeze(0)\n",
    "                text_output, _ = self.text_lstm(\n",
    "                    word_embedding, text_output.unsqueeze(0))\n",
    "                text_output = text_output[:, -1, :]\n",
    "                combined_output = torch.cat((text_output, image_output), dim=1)\n",
    "            return caption\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 133,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "\n",
    "# Define the dataset for training\n",
    "class CaptionDataset(Dataset):\n",
    "    def __init__(self, text_features, image_features, captions):\n",
    "        self.text_features = text_features\n",
    "        self.image_features = image_features\n",
    "        self.captions = captions\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.captions)\n",
    "\n",
    "    def __getitem__(self, index):\n",
    "        text_features = torch.tensor(\n",
    "            self.text_features[index], dtype=torch.float32)\n",
    "        image_features = torch.tensor(\n",
    "            self.image_features[index], dtype=torch.float32)\n",
    "        caption = self.captions[index]\n",
    "        return text_features, image_features, caption\n",
    "\n",
    "\n",
    "# Define the dataset for testing\n",
    "class CaptionTestDataset(Dataset):\n",
    "    def __init__(self, image_paths, transform=None):\n",
    "        self.image_paths = 'sentiment/' + image_paths\n",
    "        self.transform = transform\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.image_paths)\n",
    "\n",
    "    def __getitem__(self, index):\n",
    "        image_path = self.image_paths[index]\n",
    "        image = Image.open(image_path).convert('RGB')\n",
    "        if self.transform is not None:\n",
    "            image = self.transform(image)\n",
    "        return image, image_path\n",
    "    \n",
    "    \n",
    "\n",
    "# Define the transforms that should be applied to each image\n",
    "transform = transforms.Compose([\n",
    "    transforms.Resize((224, 224)),\n",
    "    transforms.ToTensor(),\n",
    "    transforms.Normalize((0.485, 0.456, 0.406),\n",
    "                            (0.229, 0.224, 0.225))\n",
    "])\n",
    "\n",
    "# Create the training and testing datasets\n",
    "train_dataset = CaptionDataset(\n",
    "    train_data['text_features'], train_data['image_features'], train_data['sentiment'])\n",
    "test_dataset = CaptionTestDataset(\n",
    "    test_data['filename'], transform=transform)\n",
    "\n",
    "# create dataloaders\n",
    "train_dataloader = DataLoader(\n",
    "    train_dataset, batch_size=32, shuffle=True, num_workers=4)\n",
    "test_dataloader = DataLoader(\n",
    "    test_dataset, batch_size=32, shuffle=False, num_workers=4)\n",
    "\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 134,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define hyperparameters\n",
    "text_input_size = 100  # size of GloVe embeddings\n",
    "image_input_size = 2048  # size of ResNet-101 features\n",
    "hidden_size = 512\n",
    "vocab_size = 10000\n",
    "\n",
    "# Instantiate model\n",
    "model = MultiModalCaptionGeneration(\n",
    "    text_input_size, image_input_size, hidden_size, vocab_size)\n",
    "\n",
    "# Define loss function and optimizer\n",
    "criterion = nn.CrossEntropyLoss()\n",
    "optimizer = optim.Adam(model.parameters(), lr=0.001)\n",
    "\n",
    "# Train the model\n",
    "num_epochs = 10\n",
    "for epoch in range(num_epochs):\n",
    "    epoch_loss = 0\n",
    "    for i, (image_features, text_features, caption) in enumerate(train_dataloader):\n",
    "        optimizer.zero_grad()\n",
    "        loss = model(text_features, image_features, caption)\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        epoch_loss += loss.item()\n",
    "    print(f\"Epoch {epoch+1} loss: {epoch_loss/i:.4f}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Set the model to evaluation mode\n",
    "model.eval()\n",
    "\n",
    "# Create lists to store the predicted captions and image paths\n",
    "predicted_captions = []\n",
    "image_paths = []\n",
    "\n",
    "# device\n",
    "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "\n",
    "# Iterate over the test dataloader\n",
    "for images, paths in test_dataloader:\n",
    "    # Move the images to the device\n",
    "    images = images.to(device)\n",
    "\n",
    "    # Process the images using the image processing module of the model\n",
    "    image_features = model.image_cnn(images)\n",
    "\n",
    "    # Initialize the text features with zeros\n",
    "    text_features = torch.zeros(\n",
    "        images.shape[0], 1, model.text_lstm.hidden_size).to(device)\n",
    "\n",
    "    # Generate captions using the model\n",
    "    captions = model(text_features, image_features)\n",
    "\n",
    "    # Convert the predicted caption indices to words\n",
    "    captions = [glove_model.idx2word[idx] for idx in captions]\n",
    "\n",
    "    # Add the predicted captions and image paths to the lists\n",
    "    predicted_captions.extend(captions)\n",
    "    image_paths.extend(paths)\n",
    "\n",
    "# Write the predicted captions to a file\n",
    "with open('predicted_captions.txt', 'w') as f:\n",
    "    for path, caption in zip(image_paths, predicted_captions):\n",
    "        f.write('{}\\t{}\\n'.format(path, caption))\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.5"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
